{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MzI3FH0iMbhP"
   },
   "source": [
    "# Achieving Image Super-Resolution using CNNs and GANs\n",
    "\n",
    "**This project aims to achieve Single Image Super Resolution using Deep Convolutional Neural Networs (SRCNN) and Generative Adersarial Networks (SRGAN)**\n",
    "\n",
    "**Dataset:** [DIV2K](https://data.vision.ee.ethz.ch/cvl/DIV2K/)\n",
    "\n",
    "**References**:\n",
    "\n",
    "**[1]** Dong, C., Loy, C.C., He, K., Tang, X., 2016. Image super-resolution using deep convolutional networks. IEEE Transactions on Pattern Analysis and Machine Intelligence 38, 295–307. doi:10.1109/TPAMI.2015.2439281.\n",
    "\n",
    "**[2]** Kim, J., Lee, J.K., Lee, K.M., 2016. Accurate image super-resolution using very deep convolutional networks, in: Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR).\n",
    "\n",
    "**[3]** Ledig, C., Theis, L., Huszar, F., Caballero, J., Cunningham, A., Acosta, A., Aitken, A., Tejani, A., Totz, J., Wang, Z., Shi, W., 2017. Photo-realistic single image super-resolution using a generative adversarial network, in: Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BpcfCXbh6NDD"
   },
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rYgFdWeVI3P3"
   },
   "outputs": [],
   "source": [
    "# Tensorflow\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Conv2D, UpSampling2D, Rescaling, LeakyReLU, PReLU\n",
    "from tensorflow.keras.utils import load_img, img_to_array, array_to_img\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers, models\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications import VGG19\n",
    "\n",
    "import tensorflow_datasets as tfds\n",
    "import tensorflow as tf\n",
    "\n",
    "# IPython\n",
    "from IPython.display import display\n",
    "from IPython.display import clear_output\n",
    "\n",
    "# Google\n",
    "from google.colab import files\n",
    "\n",
    "# Utils\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import zipfile\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1HGPzzJE4SY6"
   },
   "source": [
    "# Dataset - DIV2K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EnScNoqU6yD6"
   },
   "outputs": [],
   "source": [
    "def extract_dataset(dataset_path):\n",
    "  # Path to the tar.gz file\n",
    "  tar_file_path = dataset_path+\".tar.gz\"\n",
    "\n",
    "  # Destination directory where you want to extract the contents\n",
    "  extracted_dir = dataset_path\n",
    "\n",
    "  os.makedirs(extracted_dir, exist_ok=True)\n",
    "\n",
    "  # Extract the contents using shutil\n",
    "  with zipfile.ZipFile(tar_file_path, 'r') as zip_ref:\n",
    "      zip_ref.extractall(extracted_dir)\n",
    "\n",
    "  print(f\"Dataset extracted to: {extracted_dir}\")\n",
    "\n",
    "  ## TODO: add option to save dataset to the drive\n",
    "\n",
    "  return extracted_dir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XoMZ0Qk176ZS"
   },
   "source": [
    "## High Resolution - 2K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nzdZdK_e6kGy",
    "outputId": "c22d84b9-ffcd-4c8e-e245-2240b3ea7a14"
   },
   "outputs": [],
   "source": [
    "dataset_name = \"DIV2K_train_HR\"\n",
    "url = \"http://data.vision.ee.ethz.ch/cvl/DIV2K/DIV2K_train_HR.zip\"\n",
    "dataset_path = tf.keras.utils.get_file(dataset_name, origin=url, untar=True)\n",
    "extracted_dir = extract_dataset(dataset_path)\n",
    "\n",
    "## Extract files\n",
    "complete_dataset_path = extracted_dir + \"/\" + dataset_name\n",
    "x_train_hr = [os.path.join(complete_dataset_path, file) for file in os.listdir(complete_dataset_path) if file.endswith(('.png', '.jpg', '.jpeg'))]\n",
    "x_train_hr = sorted(x_train_hr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EfAzC4Mv7b3f",
    "outputId": "357d1f68-910d-4b12-974e-0d7bb2a33d65"
   },
   "outputs": [],
   "source": [
    "dataset_name = \"DIV2K_valid_HR\"\n",
    "url = \"http://data.vision.ee.ethz.ch/cvl/DIV2K/DIV2K_valid_HR.zip\"\n",
    "dataset_path = tf.keras.utils.get_file(dataset_name, origin=url, untar=True)\n",
    "extracted_dir = extract_dataset(dataset_path)\n",
    "\n",
    "## Extract files\n",
    "complete_dataset_path_hr = extracted_dir + \"/\" + dataset_name\n",
    "x_validation_hr = [os.path.join(complete_dataset_path_hr, file) for file in os.listdir(complete_dataset_path_hr) if file.endswith(('.png', '.jpg', '.jpeg'))]\n",
    "x_validation_hr = sorted(x_validation_hr)\n",
    "\n",
    "split_rate=0.2\n",
    "\n",
    "## Split validation dataset into test and validation\n",
    "x_test_hr = x_validation_hr[round(len(x_validation_hr)*(1-split_rate)):]\n",
    "x_validation_hr = x_validation_hr[:round(len(x_validation_hr)*(1-split_rate))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KSIOGkaT8B8e"
   },
   "source": [
    "## Low Resolution - Downscaled using bicubic x8 interpolation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PfRjuEDc7i37",
    "outputId": "3a07141c-3d39-41ee-c9ee-2ade4c0c778b"
   },
   "outputs": [],
   "source": [
    "dataset_name = \"DIV2K_train_LR_x8\"\n",
    "url = \"http://data.vision.ee.ethz.ch/cvl/DIV2K/DIV2K_train_LR_x8.zip\"\n",
    "dataset_path = tf.keras.utils.get_file(dataset_name, origin=url, untar=True)\n",
    "extracted_dir = extract_dataset(dataset_path)\n",
    "\n",
    "# Extract files\n",
    "complete_dataset_path_lr = extracted_dir + \"/\" + dataset_name\n",
    "x_train_lr_x8 = [os.path.join(complete_dataset_path_lr, file) for file in os.listdir(complete_dataset_path_lr) if file.endswith(('.png', '.jpg', '.jpeg'))]\n",
    "x_train_lr_x8 = sorted(x_train_lr_x8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sqaskbup83fz",
    "outputId": "2767ab9f-a954-4a30-f4a6-e3b4d282cd96"
   },
   "outputs": [],
   "source": [
    "dataset_name = \"DIV2K_valid_LR_x8\"\n",
    "url = \"http://data.vision.ee.ethz.ch/cvl/DIV2K/DIV2K_valid_LR_x8.zip\"\n",
    "dataset_path = tf.keras.utils.get_file(dataset_name, origin=url, untar=True)\n",
    "extracted_dir = extract_dataset(dataset_path)\n",
    "\n",
    "# Extract files\n",
    "complete_dataset_path_lr = extracted_dir + \"/\" + dataset_name\n",
    "x_validation_lr_x8 = [os.path.join(complete_dataset_path_lr, file) for file in os.listdir(complete_dataset_path_lr) if file.endswith(('.png', '.jpg', '.jpeg'))]\n",
    "x_validation_lr_x8 = sorted(x_validation_lr_x8)\n",
    "\n",
    "## Split validation dataset into test and validation\n",
    "x_test_lr_x8 = x_validation_lr_x8[round(len(x_validation_lr_x8)*(1-split_rate)):]\n",
    "x_validation_lr_x8 = x_validation_lr_x8[:round(len(x_validation_lr_x8)*(1-split_rate))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Gt5zMcBm7NQM"
   },
   "source": [
    "# Super Resolution Using CNNS (SRCNN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Aw3j4bDICxdX"
   },
   "source": [
    "## Defining the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3zZ67DXHJGKy"
   },
   "outputs": [],
   "source": [
    "def srcnn_model(input_shape, upscaling=(2,2)):\n",
    "    input_layer = Input(shape=input_shape)\n",
    "\n",
    "    # Feature extraction\n",
    "    x = Conv2D(64, (9, 9), activation='relu', padding='same')(input_layer)\n",
    "\n",
    "    # Non-linear mapping\n",
    "    x = Conv2D(32, (1, 1), activation='relu', padding='same')(x)\n",
    "\n",
    "    # Upsampling\n",
    "    x = UpSampling2D(size=upscaling)(x)\n",
    "\n",
    "    # Reconstruction\n",
    "    x = Conv2D(3, (5, 5), padding='same')(x) # No activation on the last layer\n",
    "\n",
    "    model = Model(input_layer, x)\n",
    "    model.compile(optimizer='adam', loss='mean_squared_error', metrics=[\"accuracy\"])\n",
    "\n",
    "    return model\n",
    "\n",
    "srcnn = srcnn_model(input_shape=(128,128, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "t1ST2QPNJJci",
    "outputId": "d9e4b064-34bc-4bdc-badc-bcfe637cee88"
   },
   "outputs": [],
   "source": [
    "# Model Info\n",
    "srcnn.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "w_xUiIrTC1ot"
   },
   "source": [
    "## Importing dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "99zWer_aZj-x"
   },
   "outputs": [],
   "source": [
    "input_img_size = srcnn.input_shape[1:3]\n",
    "out_img_size = srcnn.output_shape[1:3]\n",
    "num_imgs_train = len(x_train_hr)\n",
    "num_imgs_validation = len(x_validation_hr)\n",
    "num_imgs_test = len(x_test_hr)\n",
    "\n",
    "def path_to_image(path, img_size):\n",
    "    img = img_to_array(load_img(path, target_size=img_size))\n",
    "    img = img.astype(\"float32\") / 255\n",
    "    return img\n",
    "\n",
    "train_inputs = np.zeros((num_imgs_train,) + input_img_size + (3,), dtype=\"float32\")\n",
    "train_targets = np.zeros((num_imgs_train,) + out_img_size + (3,), dtype=\"float32\")\n",
    "\n",
    "for i in range(num_imgs_train):\n",
    "    train_inputs[i] = path_to_image(x_train_lr_x8[i], input_img_size)\n",
    "    train_targets[i] = path_to_image(x_train_hr[i], out_img_size)\n",
    "\n",
    "validation_inputs = np.zeros((num_imgs_validation,) + input_img_size + (3,), dtype=\"float32\")\n",
    "validation_targets = np.zeros((num_imgs_validation,) + out_img_size + (3,), dtype=\"float32\")\n",
    "\n",
    "for i in range(num_imgs_validation):\n",
    "    validation_inputs[i] = path_to_image(x_validation_lr_x8[i], input_img_size)\n",
    "    validation_targets[i] = path_to_image(x_validation_hr[i], out_img_size)\n",
    "\n",
    "test_inputs = np.zeros((num_imgs_test,) + input_img_size + (3,), dtype=\"float32\")\n",
    "test_targets = np.zeros((num_imgs_test,) + out_img_size + (3,), dtype=\"float32\")\n",
    "\n",
    "for i in range(num_imgs_test):\n",
    "    test_inputs[i] = path_to_image(x_test_lr_x8[i], input_img_size)\n",
    "    test_targets[i] = path_to_image(x_test_hr[i], out_img_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "j6bTUHztx7lF"
   },
   "source": [
    "## Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "X8-rr0MpDN8G"
   },
   "outputs": [],
   "source": [
    "callbacks = [\n",
    "    keras.callbacks.ModelCheckpoint(\"scrnn\", save_best_only=True)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CYbxCqkYeNvI",
    "outputId": "cf3efc0f-9747-4098-9049-53b10ce579e5"
   },
   "outputs": [],
   "source": [
    "history = srcnn.fit(train_inputs, train_targets, batch_size=32, epochs=5, validation_data=(validation_inputs, validation_targets), callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 17
    },
    "id": "-dWGh9SIEtVc",
    "outputId": "81fda013-9bc6-4403-d16c-fc3c8f610369"
   },
   "outputs": [],
   "source": [
    "## Save and download model\n",
    "srcnn.save('srcnn.keras')\n",
    "files.download('srcnn.keras')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3XD0a38wEm4p"
   },
   "source": [
    "## Evaluating Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 905
    },
    "id": "zCJBkmN0E7tx",
    "outputId": "16dea8cb-21c9-47d6-b867-ac1b2d1556ea"
   },
   "outputs": [],
   "source": [
    "epochs = range(1, len(history.history[\"loss\"]) + 1)\n",
    "loss = history.history[\"loss\"]\n",
    "val_loss = history.history[\"val_loss\"]\n",
    "plt.figure()\n",
    "plt.plot(epochs, loss, \"bo\", label=\"Training loss\")\n",
    "plt.plot(epochs, val_loss, \"b\", label=\"Validation loss\")\n",
    "plt.title(\"Training and validation loss\")\n",
    "plt.legend()\n",
    "\n",
    "epochs = range(1, len(history.history[\"accuracy\"]) + 1)\n",
    "accuracy = history.history[\"accuracy\"]\n",
    "val_accuracy = history.history[\"val_accuracy\"]\n",
    "plt.figure()\n",
    "plt.plot(epochs, accuracy, \"bo\", label=\"Training accuracy\")\n",
    "plt.plot(epochs, val_accuracy, \"b\", label=\"Validation accuracy\")\n",
    "plt.title(\"Training and validation accuracy\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bH9SxqyCicMK"
   },
   "source": [
    "## Plotting results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 434
    },
    "id": "KM3AvcZjiqcM",
    "outputId": "9f508e15-8fe6-491a-ef0d-64cc357f919c"
   },
   "outputs": [],
   "source": [
    "files.upload()\n",
    "srcnn = keras.models.load_model(\"srcnn.keras\")\n",
    "srcnn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "I4B07ssiHH_l",
    "outputId": "f2df1f4d-6428-4126-ef5b-05d603857a18"
   },
   "outputs": [],
   "source": [
    "test_loss, test_acc = srcnn.evaluate(train_inputs, train_targets)\n",
    "print(f\"Train accuracy: {test_acc:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "Aw4u2Cb0GC5I",
    "outputId": "47bd9c1a-0f39-40ed-d2dc-50619a90afed"
   },
   "outputs": [],
   "source": [
    "number_of_images = 10\n",
    "\n",
    "for _ in range(0,number_of_images):\n",
    "  i = random.randint(0, np.shape(test_inputs)[0]-1)\n",
    "  result_image = srcnn.predict(np.expand_dims(test_inputs[i], 0))[0]\n",
    "  plt.figure(figsize=(12,10))\n",
    "  plt.subplot(1,3,1)\n",
    "  test_image = test_inputs[i]\n",
    "  plt.axis(\"off\")\n",
    "  plt.imshow(array_to_img(test_image))\n",
    "  plt.title(\"Low Resolution\")\n",
    "  plt.subplot(1,3,2)\n",
    "  plt.axis(\"off\")\n",
    "  plt.imshow(array_to_img(result_image))\n",
    "  plt.title(\"SR\")\n",
    "  plt.subplot(1,3,3)\n",
    "  test_image = test_targets[i]\n",
    "  plt.axis(\"off\")\n",
    "  plt.imshow(array_to_img(test_image))\n",
    "  plt.title(\"Ground Truth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 899
    },
    "id": "OlJZSMyj1jNN",
    "outputId": "2a319b92-b32e-4035-c5c6-c0ad140f781c"
   },
   "outputs": [],
   "source": [
    "index = 3\n",
    "dpi = 50\n",
    "input = np.expand_dims(test_inputs[index], axis=0)\n",
    "_, height, width, depth = input.shape\n",
    "\n",
    "figsize = width / float(dpi), height / float(dpi)\n",
    "\n",
    "fig = plt.figure(figsize=figsize)\n",
    "ax = fig.add_axes([0, 0, 1, 1])\n",
    "\n",
    "\n",
    "# Display the image.\n",
    "img = np.clip(np.squeeze(input), 0, 1)\n",
    "ax.imshow(img)\n",
    "ax.axis('on')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "input = np.expand_dims(test_inputs[index], axis=0)\n",
    "generated_images = srcnn.predict(input)\n",
    "\n",
    "_, height, width, depth = generated_images.shape\n",
    "\n",
    "figsize = width / float(dpi), height / float(dpi)\n",
    "\n",
    "fig = plt.figure(figsize=figsize)\n",
    "ax = fig.add_axes([0, 0, 1, 1])\n",
    "\n",
    "\n",
    "img = np.clip(np.squeeze(generated_images), 0, 1)\n",
    "plt.imshow(img)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gQxqKKpgHfRh"
   },
   "source": [
    "## SRCNN - Deeper Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xcSLmFF3QLC-"
   },
   "outputs": [],
   "source": [
    "def srcnn_deeper_model(input_shape, upscaling=(2,2)):\n",
    "    input_layer = Input(shape=(None, None, 3))\n",
    "\n",
    "    # Feature extraction\n",
    "    x = Conv2D(64, (9, 9), activation='relu', padding='same')(input_layer)\n",
    "    x = Conv2D(64, (9, 9), activation='relu', padding='same')(x)\n",
    "\n",
    "    # Non-linear mapping\n",
    "    x = Conv2D(32, (1, 1), activation='relu', padding='same')(x)\n",
    "\n",
    "    # Upsampling para 2n x 2n\n",
    "    x = UpSampling2D(size=upscaling)(x)\n",
    "\n",
    "    # Reconstrução - output 2n x 2n image\n",
    "    x = Conv2D(32, (5, 5), activation='relu', padding='same')(x)\n",
    "    x = Conv2D(3, (5, 5),  activation='relu', padding='same')(x)\n",
    "\n",
    "    model = Model(input_layer, x)\n",
    "    model.compile(optimizer='rmsprop', loss='mean_squared_error', metrics=[\"accuracy\"])\n",
    "\n",
    "    return model\n",
    "\n",
    "srcnn = srcnn_deeper_model((128, 128))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "COiU2sh_bm0M",
    "outputId": "5e525834-902e-4b73-aa9d-a12e56e189f0"
   },
   "outputs": [],
   "source": [
    "srcnn.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qeLaJazTIDQC"
   },
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "i9XPJUeGcIfm"
   },
   "outputs": [],
   "source": [
    "callback = [\n",
    "    keras.callbacks.ModelCheckpoint(\"srcnn_deeper\",save_best_only=True)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LgeoDeY5cX3D",
    "outputId": "8cc0435c-b050-4647-b680-8937da52ac2e"
   },
   "outputs": [],
   "source": [
    "history = srcnn.fit(train_inputs,\n",
    "                            train_targets,\n",
    "                            batch_size=32,\n",
    "                            epochs=5,\n",
    "                            callbacks=callback,\n",
    "                            validation_data=(validation_inputs, validation_targets)\n",
    "                          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 17
    },
    "id": "vQOFS1Lcc1GV",
    "outputId": "412c944b-c83e-4736-f704-ee34e5d2b3ee"
   },
   "outputs": [],
   "source": [
    "srcnn.save('srcnn_deeper.keras')\n",
    "from google.colab import files\n",
    "files.download('srcnn_deeper.keras')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "X7Rm3NLWIo5b"
   },
   "source": [
    "### Evaluating results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 905
    },
    "id": "FVYw8k6IdFQf",
    "outputId": "16c63db6-415e-4f15-cc39-8ae3491040cd"
   },
   "outputs": [],
   "source": [
    "epochs = range(1, len(history.history[\"loss\"]) + 1)\n",
    "loss = history.history[\"loss\"]\n",
    "val_loss = history.history[\"val_loss\"]\n",
    "plt.figure()\n",
    "plt.plot(epochs, loss, \"bo\", label=\"Training loss\")\n",
    "plt.plot(epochs, val_loss, \"b\", label=\"Validation loss\")\n",
    "plt.title(\"Training and validation loss\")\n",
    "plt.legend()\n",
    "\n",
    "epochs = range(1, len(history.history[\"accuracy\"]) + 1)\n",
    "accuracy = history.history[\"accuracy\"]\n",
    "val_accuracy = history.history[\"val_accuracy\"]\n",
    "plt.figure()\n",
    "plt.plot(epochs, accuracy, \"bo\", label=\"Training accuracy\")\n",
    "plt.plot(epochs, val_accuracy, \"b\", label=\"Validation accuracy\")\n",
    "plt.title(\"Training and validation accuracy\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "gfuQPQ2ydKs2",
    "outputId": "9643bcd9-6262-48e3-8084-00f31da9f544"
   },
   "outputs": [],
   "source": [
    "number_of_images = 10\n",
    "\n",
    "for _ in range(0,number_of_images):\n",
    "  i = random.randint(0, np.shape(test_inputs)[0]-1)\n",
    "  result_image = srcnn.predict(np.expand_dims(test_inputs[i], 0))[0]\n",
    "  plt.figure(figsize=(12,10))\n",
    "  plt.subplot(1,3,1)\n",
    "  test_image = test_inputs[i]\n",
    "  plt.axis(\"off\")\n",
    "  plt.imshow(array_to_img(test_image))\n",
    "  plt.title(\"Low Resolution\")\n",
    "  plt.subplot(1,3,2)\n",
    "  plt.axis(\"off\")\n",
    "  plt.imshow(array_to_img(result_image))\n",
    "  plt.title(\"SR\")\n",
    "  plt.subplot(1,3,3)\n",
    "  test_image = test_targets[i]\n",
    "  plt.axis(\"off\")\n",
    "  plt.imshow(array_to_img(test_image))\n",
    "  plt.title(\"Ground Truth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NLx8o20iHroH"
   },
   "source": [
    "# Very Deep Super Resolution (VDSR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zqCcb8EQJagr"
   },
   "source": [
    "## Defining the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CJOejGlkHs-8"
   },
   "outputs": [],
   "source": [
    "def vdsr_model(scale_factor=2, num_filters=64, num_layers=20):\n",
    "    input_low_resolution = tf.keras.Input(shape=(None, None, 3))\n",
    "\n",
    "    # Initial convolution\n",
    "    x = layers.Conv2D(num_filters, 3, padding='same', activation='relu')(input_low_resolution)\n",
    "\n",
    "    # Intermediate convolutions\n",
    "    for _ in range(num_layers - 2):\n",
    "        x = layers.Conv2D(num_filters, 3, padding='same', activation='relu')(x)\n",
    "\n",
    "    # Upsampling layer\n",
    "    x = layers.Conv2DTranspose(num_filters, 3, strides=scale_factor, padding='same', activation='relu')(x)\n",
    "\n",
    "    # Final convolution\n",
    "    output_sr = layers.Conv2D(3, 3, padding='same')(x)  # No activation for the last layer\n",
    "\n",
    "    model = Model(inputs=input_low_resolution, outputs=output_sr)\n",
    "\n",
    "    model.compile(optimizer='adam', loss='mean_squared_error', metrics=[\"accuracy\"])\n",
    "\n",
    "    return model\n",
    "\n",
    "vdsr_model = vdsr_model(scale_factor=2, num_filters=64, num_layers=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "S0YxLBckJqpo",
    "outputId": "803f45d3-4b8b-40a4-bf05-07f48acee5e5"
   },
   "outputs": [],
   "source": [
    "vdsr_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cu9mILlFKM1j"
   },
   "source": [
    "## Importing dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GnuqQbS5KRHO"
   },
   "outputs": [],
   "source": [
    "input_img_size = srcnn.input_shape[1:3]\n",
    "out_img_size = srcnn.output_shape[1:3]\n",
    "num_imgs_train = len(x_train_hr)\n",
    "num_imgs_validation = len(x_validation_hr)\n",
    "num_imgs_test = len(x_test_hr)\n",
    "\n",
    "def path_to_image(path, img_size):\n",
    "    img = img_to_array(load_img(path, target_size=img_size))\n",
    "    img = img.astype(\"float32\") / 255\n",
    "    return img\n",
    "\n",
    "train_inputs = np.zeros((num_imgs_train,) + input_img_size + (3,), dtype=\"float32\")\n",
    "train_targets = np.zeros((num_imgs_train,) + out_img_size + (3,), dtype=\"float32\")\n",
    "\n",
    "for i in range(num_imgs_train):\n",
    "    train_inputs[i] = path_to_image(x_train_lr_x8[i], input_img_size)\n",
    "    train_targets[i] = path_to_image(x_train_hr[i], out_img_size)\n",
    "\n",
    "validation_inputs = np.zeros((num_imgs_validation,) + input_img_size + (3,), dtype=\"float32\")\n",
    "validation_targets = np.zeros((num_imgs_validation,) + out_img_size + (3,), dtype=\"float32\")\n",
    "\n",
    "for i in range(num_imgs_validation):\n",
    "    validation_inputs[i] = path_to_image(x_validation_lr_x8[i], input_img_size)\n",
    "    validation_targets[i] = path_to_image(x_validation_hr[i], out_img_size)\n",
    "\n",
    "test_inputs = np.zeros((num_imgs_test,) + input_img_size + (3,), dtype=\"float32\")\n",
    "test_targets = np.zeros((num_imgs_test,) + out_img_size + (3,), dtype=\"float32\")\n",
    "\n",
    "for i in range(num_imgs_test):\n",
    "    test_inputs[i] = path_to_image(x_test_lr_x8[i], input_img_size)\n",
    "    test_targets[i] = path_to_image(x_test_hr[i], out_img_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WMA3u777KRfJ"
   },
   "source": [
    "## Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iNnsKZcplGAU"
   },
   "outputs": [],
   "source": [
    "callback = [\n",
    "    keras.callbacks.ModelCheckpoint(\"vdsr\", save_best_only=True)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8CIyk-GgKkT0",
    "outputId": "4dee7d86-1ab0-489d-e432-ece0d0be4c7e"
   },
   "outputs": [],
   "source": [
    "history = vdsr_model.fit(train_inputs, train_targets, batch_size=32, epochs=3, validation_data=(validation_inputs, validation_targets), callbacks=callback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IOim4eexK14J"
   },
   "outputs": [],
   "source": [
    "## Save and download model\n",
    "vdsr_model.save('vdsr.keras')\n",
    "files.download('vdsr.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "jRXHQrtrIXWi",
    "outputId": "07c147f9-b9ed-4fbc-d139-ac9891a227a8"
   },
   "outputs": [],
   "source": [
    "files.upload()\n",
    "\n",
    "vdsr_model = keras.models.load_model(\"vdsr.keras\")\n",
    "vdsr_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i-xUo_jxLVD6"
   },
   "source": [
    "## Evaluating Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 905
    },
    "id": "7_AeVGA_LXLf",
    "outputId": "5062753c-83d8-47c6-9424-344d1e547f03"
   },
   "outputs": [],
   "source": [
    "epochs = range(1, len(history.history[\"loss\"]) + 1)\n",
    "loss = history.history[\"loss\"]\n",
    "val_loss = history.history[\"val_loss\"]\n",
    "plt.figure()\n",
    "plt.plot(epochs, loss, \"bo\", label=\"Training loss\")\n",
    "plt.plot(epochs, val_loss, \"b\", label=\"Validation loss\")\n",
    "plt.title(\"Training and validation loss\")\n",
    "plt.legend()\n",
    "\n",
    "epochs = range(1, len(history.history[\"accuracy\"]) + 1)\n",
    "accuracy = history.history[\"accuracy\"]\n",
    "val_accuracy = history.history[\"val_accuracy\"]\n",
    "plt.figure()\n",
    "plt.plot(epochs, accuracy, \"bo\", label=\"Training accuracy\")\n",
    "plt.plot(epochs, val_accuracy, \"b\", label=\"Validation accuracy\")\n",
    "plt.title(\"Training and validation accuracy\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "T7aAb2D6LhTi"
   },
   "source": [
    "## Plotting results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "6kc8DLa_p83c",
    "outputId": "73414f6a-ecba-4663-f204-78615c156371"
   },
   "outputs": [],
   "source": [
    "number_of_images = 10\n",
    "\n",
    "for _ in range(0,number_of_images):\n",
    "  i = random.randint(0, np.shape(test_inputs)[0]-1)\n",
    "  result_image = vdsr_model.predict(np.expand_dims(test_inputs[i], 0))[0]\n",
    "  plt.figure(figsize=(12,10))\n",
    "  plt.subplot(1,3,1)\n",
    "  test_image = test_inputs[i]\n",
    "  plt.axis(\"off\")\n",
    "  plt.imshow(array_to_img(test_image))\n",
    "  plt.title(\"Low Resolution\")\n",
    "  plt.subplot(1,3,2)\n",
    "  plt.axis(\"off\")\n",
    "  plt.imshow(array_to_img(result_image))\n",
    "  plt.title(\"SR\")\n",
    "  plt.subplot(1,3,3)\n",
    "  test_image = test_targets[i]\n",
    "  plt.axis(\"off\")\n",
    "  plt.imshow(array_to_img(test_image))\n",
    "  plt.title(\"Ground Truth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "k4Wfa05nLulS"
   },
   "source": [
    "# Generative Adversarial Model (SRGAN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gRnUqv7HP2xv"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8_35Vc_QP3UM"
   },
   "source": [
    "## Defining the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ArQLZzqUMYjv"
   },
   "outputs": [],
   "source": [
    "def residual_block(input):\n",
    "  x = layers.Conv2D(64, (3, 3), padding='same')(input)\n",
    "  x = layers.BatchNormalization(momentum = 0.5)(x)\n",
    "  x = PReLU(shared_axes = [1,2])(x)\n",
    "  x = layers.Conv2D(64, (3, 3), padding='same', activation = 'relu')(x)\n",
    "  x = layers.BatchNormalization(momentum = 0.5)(x)\n",
    "\n",
    "  return layers.add([input, x])\n",
    "\n",
    "def upsampling_block(input):\n",
    "  x = layers.Conv2D(64, (3, 3), padding='same')(input)\n",
    "  x = layers.UpSampling2D(size=2)(x)\n",
    "  x = PReLU(shared_axes = [1,2])(x)\n",
    "\n",
    "  return x\n",
    "\n",
    "def generator_model(input_shape, upscaling_factor=2):\n",
    "    input =  tf.keras.Input(shape=input_shape)\n",
    "\n",
    "    # Encoder\n",
    "    x = layers.Conv2D(64, (9, 9), padding='same')(input)\n",
    "    x = PReLU(shared_axes = [1,2])(x)\n",
    "    temp = x\n",
    "\n",
    "    for _ in range(32):\n",
    "        x = residual_block(x)\n",
    "\n",
    "    # Decoder\n",
    "    x = layers.Conv2D(64, (3, 3), padding='same', activation=tf.keras.layers.LeakyReLU(alpha=0.4))(x)\n",
    "    # x = layers.BatchNormalization(momentum = 0.2)(x)\n",
    "    x = layers.add([x, temp])\n",
    "    for _ in range(upscaling_factor-1):\n",
    "      x = upsampling_block(x)\n",
    "\n",
    "    # output = layers.Conv2D(3, (3, 3), padding='same', activation='sigmoid')(x)\n",
    "    output = layers.Conv2D(3, (3, 3), padding='same', activation=tf.keras.layers.LeakyReLU(alpha=0.3))(x)\n",
    "\n",
    "    model = Model(inputs=input, outputs=output)\n",
    "\n",
    "    return model\n",
    "\n",
    "def discriminator_block(input, filters, strides=1, batch_norm=True):\n",
    "  x = layers.Conv2D(filters, (3, 3), strides=strides, padding='same', activation=tf.keras.layers.LeakyReLU(alpha=0.2))(input)\n",
    "  if batch_norm:\n",
    "    x = layers.BatchNormalization(momentum = 0.5)(x)\n",
    "  x = LeakyReLU(alpha=0.2)(x)\n",
    "\n",
    "  return x\n",
    "\n",
    "# Discriminator model\n",
    "def discriminator_model(input_shape):\n",
    "    input =  tf.keras.Input(shape=input_shape)\n",
    "\n",
    "    features = 32\n",
    "\n",
    "    x = discriminator_block(input, features, batch_norm=False)\n",
    "    x = discriminator_block(x, features, strides = 2)\n",
    "    x = discriminator_block(x, features * 2)\n",
    "    x = discriminator_block(x, features * 2)\n",
    "    x = discriminator_block(x, features * 4)\n",
    "    x = discriminator_block(x, features * 8)\n",
    "    x = discriminator_block(x, features * 8)\n",
    "\n",
    "    x = layers.Flatten()(x)\n",
    "    x = layers.Dense(features)(x)  # Output a single value for real or fake\n",
    "    x = LeakyReLU(alpha=0.2)(x)\n",
    "\n",
    "    output = layers.Dense(1, activation = 'sigmoid')(x)\n",
    "\n",
    "    model = Model(inputs=input, outputs=output)\n",
    "\n",
    "    return model\n",
    "\n",
    "# GAN model combining generator and discriminator\n",
    "def gan_model(input_shape, output_shape, generator, discriminator, vgg):\n",
    "    low_resolution_input = tf.keras.Input(shape= input_shape)\n",
    "    high_resolution_input = tf.keras.Input(shape=output_shape)\n",
    "\n",
    "    generator_output = generator(low_resolution_input)\n",
    "    generated_features = vgg(generator_output)\n",
    "\n",
    "    discriminator.trainable = False  # Freeze discriminator during GAN training\n",
    "\n",
    "    discriminator_output = discriminator(generator_output)\n",
    "    model = Model(inputs=[low_resolution_input, high_resolution_input], outputs=[discriminator_output, generated_features])\n",
    "\n",
    "    return model\n",
    "\n",
    "def vgg_model(input_shape):\n",
    "  vgg = VGG19(weights='imagenet', include_top = False, input_shape = input_shape)\n",
    "\n",
    "  return Model(inputs=vgg.inputs, outputs=vgg.layers[10].output)\n",
    "\n",
    "\n",
    "# Create instances of the models\n",
    "generator = generator_model((128, 128, 3), upscaling_factor=2)\n",
    "discriminator = discriminator_model(input_shape=(256, 256, 3))\n",
    "vgg = vgg_model(input_shape=(256, 256, 3))\n",
    "\n",
    "vgg.trainable = False\n",
    "\n",
    "gan = gan_model((128, 128, 3), (256, 256, 3), generator, discriminator, vgg)\n",
    "\n",
    "generator.compile(optimizer='adam', loss='mean_squared_error')\n",
    "discriminator.compile(optimizer='adam', loss='binary_crossentropy', loss_weights=[1e-3])\n",
    "gan.compile(optimizer='adam', loss=['binary_crossentropy', 'mean_squared_error'], loss_weights=[1e-3, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rtL3zXNZPrE5",
    "outputId": "0ed3a2a5-9dea-444f-a0f1-ab4df3dd942b"
   },
   "outputs": [],
   "source": [
    "generator.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OjvT1eDvPuKl",
    "outputId": "04fbfce8-6175-4857-f9f7-035f4d071425"
   },
   "outputs": [],
   "source": [
    "discriminator.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mDzEGNl8Pwh4",
    "outputId": "58f9dfb3-4855-44de-8815-923bf0616fb9"
   },
   "outputs": [],
   "source": [
    "gan.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zV0OBgtAP8zo"
   },
   "source": [
    "## Importing dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UoLRGH-FqEYn"
   },
   "outputs": [],
   "source": [
    "input_img_size = generator.input_shape[1:3]\n",
    "out_img_size = generator.output_shape[1:3]\n",
    "\n",
    "num_imgs_train = len(x_train_hr)\n",
    "num_imgs_validation = len(x_validation_hr)\n",
    "num_imgs_test = len(x_test_hr)\n",
    "\n",
    "\n",
    "def get_img_array(img_path, target_size):\n",
    "    img = keras.utils.load_img(img_path, target_size=target_size)\n",
    "    array = keras.utils.img_to_array(img)\n",
    "    # array = array.astype(\"float32\") / 255\n",
    "    array = np.expand_dims(array, axis=0)\n",
    "    # array = keras.applications.vgg19.preprocess_input(array)\n",
    "    return array\n",
    "\n",
    "train_inputs = np.zeros((num_imgs_train,) + input_img_size + (3,), dtype=\"float32\")\n",
    "train_targets = np.zeros((num_imgs_train,) + out_img_size + (3,), dtype=\"float32\")\n",
    "\n",
    "for i in range(num_imgs_train):\n",
    "    train_inputs[i] = get_img_array(x_train_lr_x8[i], input_img_size)\n",
    "    train_targets[i] = get_img_array(x_train_hr[i], out_img_size)\n",
    "\n",
    "validation_inputs = np.zeros((num_imgs_validation,) + input_img_size + (3,), dtype=\"float32\")\n",
    "validation_targets = np.zeros((num_imgs_validation,) + out_img_size + (3,), dtype=\"float32\")\n",
    "\n",
    "for i in range(num_imgs_validation):\n",
    "    validation_inputs[i] = get_img_array(x_validation_lr_x8[i], input_img_size)\n",
    "    validation_targets[i] = get_img_array(x_validation_hr[i], out_img_size)\n",
    "\n",
    "test_inputs = np.zeros((num_imgs_test,) + input_img_size + (3,), dtype=\"float32\")\n",
    "test_targets = np.zeros((num_imgs_test,) + out_img_size + (3,), dtype=\"float32\")\n",
    "\n",
    "for i in range(num_imgs_test):\n",
    "    test_inputs[i] = get_img_array(x_test_lr_x8[i], input_img_size)\n",
    "    test_targets[i] = get_img_array(x_test_hr[i], out_img_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EevIUub1ReAL"
   },
   "source": [
    "## Training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 455
    },
    "id": "qc3wzQGaLKvo",
    "outputId": "a8d026da-e4c2-412b-9aa0-00c2f178c2da"
   },
   "outputs": [],
   "source": [
    "epochs = 1000\n",
    "plt.figure()\n",
    "\n",
    "# low_resolution_images = train_inputs[:, :, :,::-1]\n",
    "# high_resolution_images = train_targets[:, :, :,::-1]\n",
    "low_resolution_images = train_inputs\n",
    "high_resolution_images = train_targets\n",
    "\n",
    "# d_losses = [] # Create list to save values and plot it latter\n",
    "# g_losses = [] # Create list to save values and plot it latter\n",
    "\n",
    "batch_size = 1\n",
    "for epoch in range(epochs):\n",
    "\n",
    "    # Train discriminator\n",
    "    idx = np.random.randint(0, len(low_resolution_images), batch_size)\n",
    "    low_res_images = low_resolution_images[idx]\n",
    "\n",
    "    print(f\"Input shape {np.shape(low_res_images)}\")\n",
    "    # Generate fake images using the generator\n",
    "    generated_images = generator.predict(low_res_images)\n",
    "\n",
    "    oimage=low_res_images[0]\n",
    "    gimages=generated_images[0]\n",
    "\n",
    "    clear_output()\n",
    "    display(array_to_img(oimage))\n",
    "    display(array_to_img(gimages))\n",
    "\n",
    "    # Label real images as 1 and fake images as 0\n",
    "    real_labels = np.ones((batch_size, 1))\n",
    "    fake_labels = np.zeros((batch_size, 1))\n",
    "\n",
    "    real_images = high_resolution_images[idx]\n",
    "\n",
    "    # Train the discriminator on real and fake images\n",
    "    discriminator.trainable = True\n",
    "    d_loss_fake = discriminator.train_on_batch(generated_images, y=fake_labels)\n",
    "    d_loss_real = discriminator.train_on_batch(real_images, y=real_labels)\n",
    "    discriminator.trainable = False\n",
    "    d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)\n",
    "\n",
    "    d_losses.append(d_loss)\n",
    "\n",
    "    valid_labels = np.ones((batch_size, 1))\n",
    "\n",
    "    image_features = vgg.predict(real_images)\n",
    "\n",
    "    # Update the generator via the GAN model\n",
    "    generator.trainable = True\n",
    "    g_loss, _, _ = gan.train_on_batch([low_res_images, real_images], [valid_labels, image_features] )\n",
    "\n",
    "\n",
    "    g_losses.append(g_loss)\n",
    "    # Print progress and save generated images (optional)\n",
    "    if epoch % 1 == 0:\n",
    "        print(f\"Epoch {epoch}, D Loss: {d_loss}, G Loss: {g_loss}\")\n",
    "\n",
    "        # Save generated images (optional)\n",
    "        # generated_images = generator.predict(low_resolution_images[:5])\n",
    "        # Save or visualize the images as needed\n",
    "\n",
    "# Save the trained generator model\n",
    "# generator.save('super_resolution_generator.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 17
    },
    "id": "6ouFCGbE9vtG",
    "outputId": "a521acad-f720-4031-c7f2-db2edde8b7a8"
   },
   "outputs": [],
   "source": [
    "discriminator.save('discriminator.keras')\n",
    "generator.save('generator.keras')\n",
    "gan.save('gan.keras')\n",
    "\n",
    "from google.colab import files\n",
    "files.download('discriminator.keras')\n",
    "files.download('generator.keras')\n",
    "files.download('gan.keras')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "N7vZfLh-TJJx"
   },
   "source": [
    "## Evaluating results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 905
    },
    "id": "YYnIaW434vRi",
    "outputId": "6ce9ba8c-b456-494e-e0a0-049d39a53ec5"
   },
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(g_losses)\n",
    "plt.title(\"Loss generator\")\n",
    "plt.figure()\n",
    "plt.plot(d_losses)\n",
    "plt.title(\"Loss discriminator\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eeSjGhE9TXvh"
   },
   "source": [
    "## Plotting results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "zeVS3A6WTZpI",
    "outputId": "13f166b5-8c56-47fd-e395-b5d1d907c95e"
   },
   "outputs": [],
   "source": [
    "files.upload()\n",
    "\n",
    "generator = keras.models.load_model(\"generator.keras\")\n",
    "generator.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 899
    },
    "id": "SHt-o_qamWyP",
    "outputId": "47e6d143-6349-4b03-be1d-ab99f3626aeb"
   },
   "outputs": [],
   "source": [
    "index = 395\n",
    "dpi = 50\n",
    "input = np.expand_dims(train_inputs[index], axis=0)\n",
    "_, height, width, depth = input.shape\n",
    "\n",
    "figsize = width / float(dpi), height / float(dpi)\n",
    "\n",
    "fig = plt.figure(figsize=figsize)\n",
    "ax = fig.add_axes([0, 0, 1, 1])\n",
    "\n",
    "\n",
    "# Display the image.\n",
    "img = np.clip(np.squeeze(input).astype(\"float32\") / 255, 0, 1)\n",
    "ax.imshow(img)\n",
    "ax.axis('on')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "input = np.expand_dims(train_inputs[index], axis=0)\n",
    "generated_images = generator.predict(input)\n",
    "\n",
    "_, height, width, depth = generated_images.shape\n",
    "\n",
    "figsize = width / float(dpi), height / float(dpi)\n",
    "\n",
    "fig = plt.figure(figsize=figsize)\n",
    "ax = fig.add_axes([0, 0, 1, 1])\n",
    "\n",
    "\n",
    "img = np.clip(np.squeeze(generated_images).astype(\"float32\") / 255, 0, 1)\n",
    "plt.imshow(img)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 548
    },
    "id": "uH3wOMuAmbZE",
    "outputId": "92797472-f1e9-4d93-e8fb-386421d649ae"
   },
   "outputs": [],
   "source": [
    "\n",
    "dpi = 55\n",
    "input = np.expand_dims(train_inputs[index], axis=0)\n",
    "generated_images = generator.predict(input)\n",
    "\n",
    "_, height, width, depth = generated_images.shape\n",
    "\n",
    "figsize = width / float(dpi), height / float(dpi)\n",
    "\n",
    "fig = plt.figure(figsize=figsize)\n",
    "ax = fig.add_axes([0, 0, 1, 1])\n",
    "\n",
    "\n",
    "img = np.clip(np.squeeze(generated_images).astype(\"float32\") / 255, 0, 1)\n",
    "plt.imshow(img)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 17
    },
    "id": "QCwbzmlvWl4a",
    "outputId": "cb5527f7-5916-45c0-9180-d9b8230dcb87"
   },
   "outputs": [],
   "source": [
    "discriminator.save('discriminator.keras')\n",
    "files.download('discriminator.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "J8mWdAhIXG8A"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "machine_shape": "hm",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
